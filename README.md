# Case Study 2: Evidence Collection

**"What Companies Say vs. What They Do"**

**Course:** Big Data and Intelligent Analytics  
**Instructor:** Sri Krishnamurthy â€” QuantUniversity  
**Term:** Spring 2026

**Team 3:**
- Vaishnavi Srinivas
- Ishaan Samel
- Ayush Fulsundar

---

## ğŸ§  Project Overview

This project implements the **Evidence Collection layer** of the PE-OrgAIR platform. Building on **Case Study 1 (Platform Foundation)**, this case study focuses on ingesting, processing, and persisting **verifiable evidence** that reflects a company's **actual AI investment**, not just public claims.

### Evidence Types

We collect and store two types of evidence:

1. **What companies say** â†’ SEC filings (10-K, 10-Q, 8-K)
2. **What companies do** â†’ External signals (jobs, tech stack, patents, leadership)

All evidence is normalized, scored, and persisted in **Snowflake**, forming the foundation for AI-readiness scoring in future case studies.

---

## âš–ï¸ System Architecture

### High-level Flow
```
External Sources
â”œâ”€â”€ SEC EDGAR (10-K, 10-Q, 8-K)
â”œâ”€â”€ Job Boards (Indeed, Google Jobs)
â”œâ”€â”€ Technology Stack (BuiltWith / SimilarTech)
â”œâ”€â”€ Patents (USPTO - mock)
â””â”€â”€ Leadership Profiles (manual / CSV / mock)
    â†“
Evidence Collection Pipelines
    â†“
Snowflake (Documents, Chunks, Signals, Summaries)
```

### Key Design Principle

**SEC filings capture *intent*, while external signals capture *execution*.**

---

## ğŸ“‚ Project Structure
```
PE_OrgAIR_CaseStudy2/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ sec_edgar.py
â”‚   â”‚   â”œâ”€â”€ document_parser.py
â”‚   â”‚   â”œâ”€â”€ job_signals.py
â”‚   â”‚   â”œâ”€â”€ tech_signals.py
â”‚   â”‚   â”œâ”€â”€ patent_signals.py
â”‚   â”‚   â”œâ”€â”€ leadership_signals.py
â”‚   â”‚   â””â”€â”€ external_signals_orchestrator.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ document.py
â”‚   â”‚   â”œâ”€â”€ signal.py
â”‚   â”‚   â””â”€â”€ evidence.py
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ snowflake.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_external_signals.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ samples/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ evidence_report.md
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ“Š Evidence Pipelines Implemented

### 1ï¸âƒ£ SEC EDGAR Pipeline (Lab 3)

- Downloads **10-K, 10-Q, 8-K** filings for 10 target companies
- Supports **PDF and HTML** formats
- Extracts AI-relevant sections:
  - Item 1 â€“ Business
  - Item 1A â€“ Risk Factors
  - Item 7 â€“ MD&A
- Implements **semantic chunking with overlap**
- Deduplicates documents using **SHA-256 content hashing**
- Tracks document lifecycle via a **document registry**

**Stored in:**
- `documents`
- `document_chunks`

---

### 2ï¸âƒ£ External Signals Pipeline (Lab 4)

#### ğŸ”¹ Technology Hiring Signals

- Scrapes job postings from **Indeed & Google Jobs**
- Filters AI-related roles using keyword and skill heuristics
- Normalizes hiring intensity to a **0â€“100 score**
- Handles company aliases (e.g., JPMorgan, Chase, JPMC)

#### ğŸ”¹ Digital Presence Signals

- Detects AI-related technologies (ML frameworks, cloud ML, AI APIs)
- Scores based on:
  - Number of AI technologies
  - Coverage across AI categories

#### ğŸ”¹ Innovation / Patent Signals

- Mock USPTO ingestion
- Scores AI patent volume, recency, and category diversity

#### ğŸ”¹ Leadership Signals

- Executive-level AI commitment scoring
- Uses role-weighted and indicator-based scoring
- One signal per executive, aggregated at company level

**Stored in:**
- `external_signals`
- `company_signal_summaries`

---

## ğŸ—„ï¸ Data Persistence (Snowflake)

### Core Tables

- `documents`
- `document_chunks`
- `external_signals`
- `company_signal_summaries`

### Key Guarantees

- All signals stored with rich metadata (JSON VARIANT)
- Scores normalized to **0â€“100**
- Composite score computed using weighted aggregation
- Signals traceable to source and timestamp

---

## ğŸ“ˆ Scoring Model

| Signal Category | Weight |
|----------------|--------|
| Technology Hiring | 0.30 |
| Innovation Activity | 0.25 |
| Digital Presence | 0.25 |
| Leadership Signals | 0.20 |

**Composite Score = weighted sum of all four categories.**

---

## â–¶ï¸ How to Run

### Run External Signals for a Company
```bash
poetry run python scripts/run_external_signals.py \
  --company-id <UUID> \
  --query "machine learning engineer" \
  --location "United States" \
  --sources indeed,google \
  --max-per-source 25
```

### Verify Data in Snowflake
```sql
SELECT * FROM external_signals;
SELECT * FROM company_signal_summaries;
```

---

## ğŸ“„ Evidence Report

The detailed **Evidence Collection Report** is available here:

- `docs/evidence_report.md`

**Includes:**
- Company-wise document counts
- Signal scores by category
- Composite scores
- Observed "say vs do" gaps
- Data quality notes

---

## ğŸ¯ Next Steps

This evidence layer feeds into **Case Study 3: AI-Readiness Scoring**, where we'll build machine learning models to predict company AI maturity based on the collected evidence.

---

## ğŸ“¦ Requirements

See `requirements.txt` for full dependencies. Key packages:
- `snowflake-connector-python`
- `requests`
- `beautifulsoup4`
- `python-dotenv`
- `pandas`

---

## ğŸ‘¥ Team Contributions

- **Vaishnavi Srinivas** â€“ External signals orchestration
- **Ishaan Samel** â€“ Snowflake integration, data quality validation
- **Ayush Fulsundar** â€“ scoring modelSEC EDGAR pipeline, document processing

---

## ğŸ“ License

Academic project for QuantUniversity â€” Spring 2026
